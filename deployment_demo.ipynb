{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wavenet_model import *\n",
    "from audio_data import WavenetDataset\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "ltype = torch.LongTensor\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('use gpu')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    ltype = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveNetModel(layers=10,\n",
    "                     blocks=3,\n",
    "                     dilation_channels=32,\n",
    "                     residual_channels=32,\n",
    "                     skip_channels=1024,\n",
    "                     end_channels=512, \n",
    "                     output_length=16,\n",
    "                     dtype=dtype, \n",
    "                     bias=True)\n",
    "model = load_latest_model_from('snapshots', use_cuda=use_cuda)\n",
    "\n",
    "model.dtype = dtype\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "else:\n",
    "    model.cpu()\n",
    "    \n",
    "print('model: ', model)\n",
    "print('receptive field: ', model.receptive_field)\n",
    "print('parameter count: ', model.parameter_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WavenetDataset(dataset_file='train_samples/bach_chaconne/dataset.npz',\n",
    "                      item_length=model.receptive_field + model.output_length - 1,\n",
    "                      target_length=model.output_length,\n",
    "                      file_location='train_samples/bach_chaconne',\n",
    "                      test_stride=500)\n",
    "print('the dataset has ' + str(len(data)) + ' items')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import onnx\n",
    "import shutil\n",
    "from timeit import default_timer as timer\n",
    "import vai_q_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.rand(1, 256, 3070)\n",
    "\n",
    "start = timer()\n",
    "for _ in range(100):\n",
    "    model(input_data)\n",
    "pytorch_total = timer() - start\n",
    "\n",
    "print(f\"Inference Time: {pytorch_total / 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prog_callback(step, total_steps):\n",
    "    print(str(100 * step // total_steps) + \"% generated\")\n",
    "\n",
    "start_data = data[260000][0] # use start data from the data set\n",
    "start_data = torch.max(start_data, 0)[1] # convert one hot vectors to integers\n",
    "\n",
    "start = timer()\n",
    "generated = model.generate(num_samples=160000,\n",
    "                           first_samples=start_data,\n",
    "                           temperature=1.0,)\n",
    "pytorch_total = timer() - start\n",
    "\n",
    "print(f\"Generation Time: {pytorch_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX Runtime (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep for ONNX export\n",
    "inputs = {\"x\": torch.rand(1, 256, 3070)}\n",
    "input_names = ['input']\n",
    "output_names = ['output']\n",
    "dynamic_axes = {'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "model_path = \"models/wavenet.onnx\"\n",
    "\n",
    "# Call export function\n",
    "torch.onnx.export(\n",
    "        model,\n",
    "        inputs,\n",
    "        model_path,\n",
    "        export_params=True,\n",
    "        opset_version=13,  # Recommended opset\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        dynamic_axes=dynamic_axes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the quantized ONNZ Model\n",
    "model_path = r'./models/wavenet.onnx'\n",
    "onnx_model = onnx.load(model_path)\n",
    "\n",
    "cpu_options = onnxruntime.SessionOptions()\n",
    "\n",
    "# Create Inference Session to run the quantized model on the CPU\n",
    "cpu_session = onnxruntime.InferenceSession(\n",
    "    onnx_model.SerializeToString(),\n",
    "    providers = ['CPUExecutionProvider'],\n",
    "    sess_options=cpu_options,\n",
    ")\n",
    "\n",
    "# Run Inference\n",
    "start = timer()\n",
    "for _ in range(100):\n",
    "    cpu_results = cpu_session.run(None, {\"input\": input_data.numpy()})\n",
    "cpu_total = timer() - start\n",
    "\n",
    "print(f\"Inference Time: {cpu_total / 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,\n",
    "             num_samples,\n",
    "             first_samples=None,\n",
    "             temperature=1.,\n",
    "             session=None):\n",
    "    model.eval()\n",
    "    if first_samples is None:\n",
    "        first_samples = model.dtype(1).zero_()\n",
    "    generated = Variable(first_samples, volatile=True)\n",
    "\n",
    "    num_pad = model.receptive_field - generated.size(0)\n",
    "    if num_pad > 0:\n",
    "        generated = constant_pad_1d(generated, model.scope, pad_start=True)\n",
    "        print(\"pad zero\")\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        input = Variable(torch.FloatTensor(1, model.classes, model.receptive_field).zero_())\n",
    "        input = input.scatter_(1, generated[-model.receptive_field:].view(1, -1, model.receptive_field), 1.)\n",
    "\n",
    "        x = torch.tensor(session.run(None, {\"input\": input.numpy()})[0])[:, :, -1].squeeze()\n",
    "\n",
    "        if temperature > 0:\n",
    "            x /= temperature\n",
    "            prob = F.softmax(x, dim=0)\n",
    "            prob = prob.cpu()\n",
    "            np_prob = prob.data.numpy()\n",
    "            x = np.random.choice(model.classes, p=np_prob)\n",
    "            x = Variable(torch.LongTensor([x]))#np.array([x])\n",
    "        else:\n",
    "            x = torch.max(x, 0)[1].float()\n",
    "\n",
    "        generated = torch.cat((generated, x), 0)\n",
    "\n",
    "    generated = (generated / model.classes) * 2. - 1\n",
    "    mu_gen = mu_law_expansion(generated, model.classes)\n",
    "\n",
    "    model.train()\n",
    "    return mu_gen\n",
    "\n",
    "start = timer()\n",
    "generated = generate(model=model,\n",
    "                     num_samples=160000,\n",
    "                     first_samples=start_data,\n",
    "                     temperature=1.0,\n",
    "                     session=cpu_session)\n",
    "cpu_total = timer() - start\n",
    "\n",
    "print(f\"Generation Time: {cpu_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX Runtime (NPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to make sure we compile everytime, otherwise the tools will use the cached version\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "directory_path = os.path.join(current_directory,  r'cache\\wavenet_cache')\n",
    "cache_directory = os.path.join(current_directory,  r'cache')\n",
    "\n",
    "# Check if the directory exists and delete it if it does.\n",
    "if os.path.exists(directory_path):\n",
    "    shutil.rmtree(directory_path)\n",
    "    print(f\"Directory deleted successfully. Starting Fresh.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory_path}' does not exist.\")\n",
    "\n",
    "# Point to the config file path used for the VitisAI Execution Provider\n",
    "config_file_path = \"vaip_config.json\"\n",
    "\n",
    "aie_options = onnxruntime.SessionOptions()\n",
    "\n",
    "aie_session = onnxruntime.InferenceSession(\n",
    "    onnx_model.SerializeToString(),\n",
    "    providers=['VitisAIExecutionProvider'],\n",
    "    sess_options=aie_options,\n",
    "    provider_options = [{'config_file': config_file_path,\n",
    "                         'cacheDir': cache_directory,\n",
    "                         'cacheKey': 'wavenet_cache'}]\n",
    ")\n",
    "\n",
    "# Run Inference\n",
    "npu_results = aie_session.run(None, {\"input\": input_data.numpy()})\n",
    "start = timer()\n",
    "for _ in range(100):\n",
    "    npu_results = aie_session.run(None, {\"input\": input_data.numpy()})\n",
    "npu_total = timer() - start\n",
    "\n",
    "print(f\"Inference Time: {npu_total / 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "generated = generate(model=model,\n",
    "                     num_samples=160000,\n",
    "                     first_samples=start_data,\n",
    "                     temperature=1.0,\n",
    "                     session=aie_session)\n",
    "npu_total = timer() - start\n",
    "\n",
    "print(f\"Generation Time: {npu_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(generated, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write('wav/generated_clip1.wav', generated, 16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
